---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = ">",
  fig.path = "man/figures/README-"
)
```

```{r library, echo = FALSE}
library(packageRank)
```

## packageRank: compute and visualize package download counts and rank percentiles

['packageRank'](https://CRAN.R-project.org/package=packageRank) is an R package that helps put package download counts into context. It does so via two functions, `cranDownloads()` and `packageRank()`, and one set of filters that remove "invalid" entries from the download logs.

In [Part I Package Download Counts](#i---computing-package-download-counts), I discuss how `cranDownloads()` extends the functionality of [`cranlogs::cran_downloads()`](https://r-hub.github.io/cranlogs/) by adding a more user-friendly interface and providing a generic R `plot()` method to makes visualization easy.

In [Part II Package Download Rank Percentiles](#ii---computing-package-download-rank-percentiles), I discuss how `packageRank()` uses rank percentiles, a nonparametric statistic that tells you the percentage of observations (i.e., packages) with fewer counts (i.e., downloads), helps you see how your package is doing relative to _all_ other [CRAN](https://CRAN.R-project.org/) packages.

In [Part III Package Download Filters](#iii---filtering-package-download-counts), I discuss how I use various filters to reduce software and behavioral artifacts (e.g., downloads that are too "small" and efforts to download all of [CRAN](https://CRAN.R-project.org/)) that inflate the package download count.

In [Part IV Notes and Miscellanea](#iv---notes-and-miscellanea), I discuss some technical issues that may be of interest to users. This includes the use of memoization, time zone issues when downloading the latest log files, and internet connection time out problems that emerged with R 4.0.3.

[‘packageRank'](https://CRAN.R-project.org/package=packageRank) requires an active internet connection, and relies on the [‘cranlogs'](https://CRAN.R-project.org/package=cranlogs) package and [RStudio's download logs](http://cran-logs.rstudio.com/). The latter record traffic to the [“0-Cloud” mirror](https://cloud.R-project.org), which is “currently sponsored by RStudio” and was previously RStudio's CRAN mirror.

Note that logs for the previous day are generally posted by 17:00 UTC. Updated results for functions that rely on [‘cranlogs'](https://CRAN.R-project.org/package=cranlogs) are typically available soon thereafter.

### getting started

To install 'packageRank' from CRAN:

```{r cran_install, eval = FALSE}
install.packages("packageRank")
```

To install the development version from GitHub:

```{r gh_install, eval = FALSE}
# You may need to first install 'remotes' via install.packages("remotes").
remotes::install_github("lindbrook/packageRank", build_vignettes = TRUE)
```

### I - computing package download counts

`cranDownloads()` uses all the same arguments as `cranlogs::cran_downloads()`:

```{r cran_downloads, eval = FALSE}
cranlogs::cran_downloads(packages = "HistData")
```
```{r cran_downloads_code, echo = FALSE}
cranlogs::cran_downloads(packages = "HistData", from = "2020-05-01", to = "2020-05-01")
```

The only difference is that `cranDownloads()` adds four features:

#### i) "spell check" for package names

```{r spell_check_fail, eval = FALSE}
cranDownloads(packages = "GGplot2")
```
```
## Error in cranDownloads(packages = "GGplot2") :
##   GGplot2: misspelled or not on CRAN.
```

<br/>
```{r spell_check_pass, eval = FALSE}
cranDownloads(packages = "ggplot2")
```
```{r spell_check_pass_code, echo = FALSE}
cranDownloads(packages = "ggplot2", from = "2020-05-01", to = "2020-05-01")
```

<br/>
This also works for inactive or "retired" packages in the [Archive](https://CRAN.R-project.org/src/contrib/Archive/):

```{r check_archive_fail, eval = FALSE}
cranDownloads(packages = "vr")
```
```
## Error in cranDownloads(packages = "vr") :
##  vr: misspelled or not on CRAN/Archive.
```

<br/>
```{r check_archive_pass, eval = FALSE}
cranDownloads(packages = "VR")
```
```{r check_archive_pass_code, echo = FALSE}
cranDownloads(packages = "VR", from = "2020-05-01", to = "2020-05-01")
```

<br/>

#### ii) two additional date formats

With `cranlogs::cran_downloads()`, you specify a time frame using the `from` and `to` arguments. The downside of this is that you _must_ use the "yyyy-mm-dd" date format. For convenience's sake, `cranDownloads()` also allows you to use "yyyy-mm" or "yyyy" (yyyy also works).

##### "yyyy-mm"
Let's say you want the download counts for ['HistData'](https://CRAN.R-project.org/package=HistData) for the month of February 2020. With `cranlogs::cran_downloads()`, you'd have to type out the whole date and remember that 2020 was a leap year:

```{r yyyy-mm_1, eval = FALSE}
cranlogs::cran_downloads(packages = "HistData", from = "2020-02-01",
  to = "2020-02-29")
```

<br/>
With `cranDownloads()`, you can just specify the year and month:

```{r yyyy-mm_2, eval = FALSE}
cranDownloads(packages = "HistData", from = "2020-02", to = "2020-02")
```

##### "yyyy" or yyyy
Let's say you want the year-to-date download counts for ['rstan'](https://CRAN.R-project.org/package=rstan). With `cranlogs::cran_downloads()`, you'd type something like:

```{r yyyy_1, eval = FALSE}
cranlogs::cran_downloads(packages = "rstan", from = "2021-01-01",
  to = Sys.Date() - 1)
```

<br/>
With `cranDownloads()`, you can use:

```{r yyyy_2, eval = FALSE}
cranDownloads(packages = "rstan", from = "2021")
```

or

```{r yyyy_3, eval = FALSE}
cranDownloads(packages = "rstan", from = 2021)
```

<br/>

#### iii) check date validity

```{r check_date, eval = FALSE}
cranDownloads(packages = "HistData", from = "2019-01-15",
  to = "2019-01-35")
```
```
## Error in resolveDate(to, type = "to") : Not a valid date.
```

#### iv) cumulative count

```{r cranDownloads_cumulative, eval = FALSE}
cranDownloads(packages = "HistData", when = "last-week")
```

```{r cranDownloads_cumulative_code, echo = FALSE}
cranDownloads(packages = "HistData", from = "2020-05-01", to = "2020-05-07")
```


<br/>

### visualizing package download counts

`cranDownloads()` makes visualizing package downloads easy. Just use `plot()`:

```{r cranDownloads_viz1, fig.align = "center"}
plot(cranDownloads(packages = "HistData", from = "2019", to = "2019"))
```

If you pass a vector of package names for a single day, `plot()` will return a dotchart:

```{r cranDownloads_viz2a, fig.align = "center"}
plot(cranDownloads(packages = c("ggplot2", "data.table", "Rcpp"),
  from = "2020-03-01", to = "2020-03-01"))
```

If you pass a vector of package names for multiple days, `plot()` uses `ggplot2` facets:

```{r cranDownloads_viz2, fig.align = "center"}
plot(cranDownloads(packages = c("ggplot2", "data.table", "Rcpp"),
  from = "2020", to = "2020-03-20"))
```
<br/>

If you want to plot those data in a single frame, set `multi.plot = TRUE`:

```{r cranDownloads_viz3}
plot(cranDownloads(packages = c("ggplot2", "data.table", "Rcpp"),
  from = "2020", to = "2020-03-20"), multi.plot = TRUE)
```

<br/>
If you want plot those data in separate plots on the same scale, use `graphics = "base"` and you'll be prompted for each plot:

```{r cranDownloads_viz4, eval = FALSE}
plot(cranDownloads(packages = c("ggplot2", "data.table", "Rcpp"),
  from = "2020", to = "2020-03-20"), graphics = "base")
```

If you want do the above on separate independent scales, set `same.xy = FALSE`:

```{r cranDownloads_viz5, eval = FALSE}
plot(cranDownloads(packages = c("ggplot2", "data.table", "Rcpp"),
  from = "2020", to = "2020-03-20"), graphics = "base", same.xy = FALSE)
```

#### `packages = NULL`

`cranlogs::cran_download(packages = NULL)` computes the total number of package downloads from CRAN. You can plot these data by using:

```{r null_packages}
plot(cranDownloads(from = 2019, to = 2019))
```

#### `packages = "R"`

`cranlogs::cran_download(packages = "R")` computes the total number of downloads of the R application (note that you can only use "R" or a vector of packages names, not both!). You can plot these data by using:

```{r r_downloads}
plot(cranDownloads(packages = "R", from = 2019, to = 2019))
```

#### smoothers and confidence intervals

To add a lowess smoother to your plot, use `smooth = TRUE`:

```{r lowess}
plot(cranDownloads(packages = "rstan", from = "2019", to = "2019"),
  smooth = TRUE)
```

With graphs that use 'ggplot2', `se = TRUE` will add confidence intervals:

```{r ci}
plot(cranDownloads(packages = c("HistData", "rnaturalearth", "Zelig"),
  from = "2020", to = "2020-03-20"), smooth = TRUE, se = TRUE)
```

#### package and R release dates

To annotate a graph with a package's release dates:

```{r pkg_release_date}
plot(cranDownloads(packages = "rstan", from = "2019", to = "2019"),
  package.version = TRUE)
```

To annotate a graph with R release dates:

```{r r_release_date}
plot(cranDownloads(packages = "rstan", from = "2019", to = "2019"),
  r.version = TRUE)
```

#### plot growth curves (cumulative download counts)

To plot growth curves, set `statistic = "cumulative"`:

```{r cranDownloads_growth_curves}
plot(cranDownloads(packages = c("ggplot2", "data.table", "Rcpp"),
  from = "2020", to = "2020-03-20"), statistic = "cumulative",
  multi.plot = TRUE, points = FALSE)
```

#### population plot

To visualize a package's downloads relative to "all" other packages over time:

```{r pop_plot, eval = FALSE}
plot(cranDownloads(packages = "HistData", from = "2020", to = "2020-03-20"),
  population.plot = TRUE)
```

```{r pop_plot_code, echo = FALSE}
plot(cranDownloads(packages = "HistData", from = "2020", to = "2020-03-20"),
  population.plot = TRUE, population.seed = 1)
```

This longitudinal view of package downloads plots the date (x-axis) against the logarithm of a package's downloads (y-axis). In the background, the same variable are plotted (in gray) using a stratified random sample of packages: within each 5% interval of rank percentiles (e.g., 0 to 5, 5 to 10, 95 to 100, etc.), a random sample of 5% of packages is selected and tracked. This graphically approximates the "typical" pattern of downloads on CRAN for the selected time period.

### II - computing package download rank percentiles

Looking at nominal download count data leads one to the "compared to what?" question. For instance, consider the data for the first week of March 2020:

```{r motivation, eval = FALSE}
plot(cranDownloads(packages = "cholera", from = "2020-03-01",
  to = "2020-03-07"))
```

```{r motivation_code, echo = FALSE, fig.align = "center"}
par(mar = c(5, 4, 4, 4))
plot(cranDownloads(packages = "cholera", from = "2020-03-01",
  to = "2020-03-07"))
par(mar = c(5, 4, 4, 2))
```

Do Wednesday and Saturday reflect surges of interest in the package or surges of traffic to [CRAN](https://CRAN.R-project.org/)? To put it differently, how can we know if a given download count is typical or unusual? One way to answer these questions is to locate your package in the frequency distribution of download counts.

Below are the distributions of logarithm of download counts for Wednesday and Saturday. The location of a vertical segment along the x-axis represents a download count and the height of a segment represents that download count's frequency. The location of ['cholera'](https://CRAN.R-project.org/package=cholera) in the distribution is highlighted in red.

```{r packageDistribution, echo = FALSE}
plot_package_distribution <- function(dat, xlim, ylim) {
  freq.dist <- dat$freq.dist
  freqtab <- dat$freqtab
  plot(freq.dist$count, freq.dist$frequency, type = "h", log = "x",
    xlab = "Downloads", ylab = "Frequency", xlim = xlim, ylim = ylim)
  axis(3, at = freqtab[1], cex.axis = 0.8, padj = 0.9, col.axis = "dodgerblue",
    col.ticks = "dodgerblue", labels = paste(names(freqtab[1]), "=",
    format(freqtab[1], big.mark = ",")))
  abline(v = freqtab[1], col = "dodgerblue", lty = "dotted")

  if (!is.null(dat$package)) {
    pkg.ct <- freqtab[names(freqtab) == dat$package]
    pkg.bin <- freqtab[freqtab == pkg.ct]
    axis(3, at = pkg.ct, labels = format(pkg.ct, big.mark = ","),
      cex.axis = 0.8, padj = 0.9, col.axis = "red", col.ticks = "red")
    abline(v = pkg.ct, col = grDevices::adjustcolor("red", alpha.f = 0.5))
    day <- weekdays(as.Date(dat$date), abbreviate = TRUE)
    title(paste0(dat$package, " @ ", dat$date, " (", day, ")"))
  } else title(paste("Distribution of Package Download Counts:", dat$date))
}

distn.data <- lapply(c("2020-03-04", "2020-03-07"), function(date) packageDistribution(package = "cholera", date = date))

xlim <- range(lapply(distn.data, function(x) x$freq.dist$count))
ylim <- range(lapply(distn.data, function(x) x$freq.dist$frequency))
```

```{r packageDistribution_wed, eval = FALSE}
plot(packageDistribution(package = "cholera", date = "2020-03-04"))
```
```{r packageDistribution_wed_code, echo = FALSE, fig.align = "center"}
plot_package_distribution(distn.data[[1]], xlim, ylim)
```

```{r packageDistribution_sat, eval = FALSE}
plot(packageDistribution(package = "cholera", date = "2020-03-07"))
```
```{r packageDistribution_sat_code, echo = FALSE, fig.align = "center"}
plot_package_distribution(distn.data[[2]], xlim, ylim)
```

While these plots give us a better picture of where ['cholera'](https://CRAN.R-project.org/package=cholera) is located, comparisons between Wednesday and Saturday are impressionistic at best: all we can confidently say is that the download counts for both days were greater than the mode.

To facilitate interpretation and comparison, I use the _rank percentile_ of a download count in place of the nominal download count. This nonparametric statistic tells you the percentage of packages with fewer downloads. In other words, it gives you the location of your package relative to the locations of all other packages. More importantly, by rescaling download counts to lie on the bounded interval between 0 and 100, rank percentiles make it easier to compare packages within and across distributions.

For example, we can compare Wednesday ("2020-03-04") to Saturday ("2020-03-07"):

```{r packageRank1}
packageRank(package = "cholera", date = "2020-03-04")
```

On Wednesday, we can see that ['cholera'](https://CRAN.R-project.org/package=cholera) had 38 downloads, came in 5,556th place out of 18,038 unique packages downloaded, and earned a spot in the 68th percentile.

```{r packageRank2}
packageRank(package = "cholera", date = "2020-03-07")
```

On Saturday, we can see that ['cholera'](https://CRAN.R-project.org/package=cholera) had 29 downloads, came in 3,061st place out of 15,950 unique packages downloaded, earned a spot in the 80th percentile.

So contrary to what the nominal counts tell us, one could say that the interest in ['cholera'](https://CRAN.R-project.org/package=cholera) was actually greater on Saturday than on Wednesday.

#### computing rank percentile

To compute rank percentiles, I do the following. For each package, I tabulate the number of downloads and then compute the percentage of packages with fewer downloads. Here are the details using ['cholera'](https://CRAN.R-project.org/package=cholera) from Wednesday as an example:

```{r percentile}
pkg.rank <- packageRank(packages = "cholera", date = "2020-03-04")

downloads <- pkg.rank$freqtab

round(100 * mean(downloads < downloads["cholera"]), 1)
```

To put it differently:

```{r percentile2}
(pkgs.with.fewer.downloads <- sum(downloads < downloads["cholera"]))

(tot.pkgs <- length(downloads))

round(100 * pkgs.with.fewer.downloads / tot.pkgs, 1)
```

#### nominal ranks

In the example above, 38 downloads puts 'cholera' in 5,556th place among the 18,038 packages downloaded. This rank is "nominal" because it's possible that multiple packages can have the same number of downloads. As a result, a package's nominal rank (but not its rank percentile) can be affected by its name: packages with the same number of downloads are sorted in alphabetical order. Thus, 'cholera' benefits from the fact that it is 31st in the list of 263 packages with 38 downloads:

```{r nominal}
pkg.rank <- packageRank(packages = "cholera", date = "2020-03-04")
downloads <- pkg.rank$freqtab

which(names(downloads[downloads == 38]) == "cholera")
length(downloads[downloads == 38])
```

### visualizing package download rank percentiles

To visualize `packageRank()`, use `plot()`.

```{r packageRank_plot_wed, eval = FALSE}
plot(packageRank(packages = "cholera", date = "2020-03-04"))
```

```{r packageRank_data, echo = FALSE}
dat <- lapply(c("2020-03-04", "2020-03-07"), function(x) {
  packageRank("cholera", date = x)
})

freqtab1 <- dat[[1]]$freqtab
freqtab2 <- dat[[2]]$freqtab
xlim <- range(seq_along(freqtab1), seq_along(freqtab2))
ylim <- range(c(freqtab1), c(freqtab2))
```

```{r packageRank_plot_code_wed, echo = FALSE, fig.align = "center"}

freqtab <- dat[[1]]$freqtab
package.data <- dat[[1]]$package.data
pkg <- dat[[1]]$packages
date <- dat[[1]]$date
y.max <- freqtab[1]
q <- stats::quantile(freqtab)[2:4]

iqr <- vapply(c("75%", "50%", "25%"), function(id) {
  dat <- which(freqtab > q[[id]])
  dat[length(dat)]
}, numeric(1L))

plot(seq_along(freqtab), c(freqtab), type = "l", xlab = "Rank",
  ylab = "log10(Count)", log = "y", xlim = xlim, ylim = ylim)
abline(v = iqr, col = "black", lty = "dotted")
iqr.labels <- c("75th", "50th", "25th")
invisible(lapply(seq_along(iqr), function(i) {
  text(iqr[[i]], y.max / 2, labels = iqr.labels[i], cex = 0.75)
}))
abline(v = which(names(freqtab) == pkg), col = "red")
abline(h = freqtab[pkg], col = "red")
pct <- package.data[package.data$package == pkg, "percentile"]
pct.label <- paste0(round(pct, 2), "%")
axis(3, at = which(names(freqtab) == pkg), padj = 0.9, col.axis = "red",
  col.ticks = "red", labels = pct.label, cex.axis = 0.8)
axis(4, at = freqtab[pkg], col.axis = "red", col.ticks = "red",
  cex.axis = 0.8, labels = format(freqtab[pkg], big.mark = ","))
points(which(names(freqtab) == pkg), freqtab[pkg], col = "red")
points(which(names(freqtab) == names(freqtab[1])), y.max,
  col = "dodgerblue")
text(which(names(freqtab) == names(freqtab[1])), y.max, pos = 4,
  labels = paste(names(freqtab[1]), "=", format(freqtab[1],
  big.mark = ",")), cex = 0.8, col = "dodgerblue")
text(max(xlim), max(ylim),
  labels = paste("Tot = ", format(sum(freqtab), big.mark = ",")), cex = 0.8,
  col = "dodgerblue", pos = 2)
day <- weekdays(as.Date(date), abbreviate = TRUE)
title(main = paste0(pkg, " @ ", date, " (", day, ")"))
```

<br/>

```{r packageRank_plot_sat, eval = FALSE}
plot(packageRank(packages = "cholera", date = "2020-03-07"))
```

```{r packageRank_plot_code_sat, echo = FALSE, fig.align = "center"}
freqtab <- dat[[2]]$freqtab
package.data <- dat[[2]]$package.data
pkg <- dat[[2]]$packages
date <- dat[[2]]$date
y.max <- freqtab[1]
q <- stats::quantile(freqtab)[2:4]

iqr <- vapply(c("75%", "50%", "25%"), function(id) {
  dat <- which(freqtab > q[[id]])
  dat[length(dat)]
}, numeric(1L))

plot(seq_along(freqtab), c(freqtab), type = "l", xlab = "Rank",
  ylab = "log10(Count)", log = "y", xlim = xlim, ylim = ylim)
abline(v = iqr, col = "black", lty = "dotted")
iqr.labels <- c("75th", "50th", "25th")
invisible(lapply(seq_along(iqr), function(i) {
  text(iqr[[i]], y.max / 2, labels = iqr.labels[i], cex = 0.75)
}))
abline(v = which(names(freqtab) == pkg), col = "red")
abline(h = freqtab[pkg], col = "red")
pct <- package.data[package.data$package == pkg, "percentile"]
pct.label <- paste0(round(pct, 2), "%")
axis(3, at = which(names(freqtab) == pkg), padj = 0.9, col.axis = "red",
  col.ticks = "red", labels = pct.label, cex.axis = 0.8)
axis(4, at = freqtab[pkg], col.axis = "red", col.ticks = "red",
  cex.axis = 0.8, labels = format(freqtab[pkg], big.mark = ","))
points(which(names(freqtab) == pkg), freqtab[pkg], col = "red")
points(which(names(freqtab) == names(freqtab[1])), y.max,
  col = "dodgerblue")
text(which(names(freqtab) == names(freqtab[1])), y.max, pos = 4,
  labels = paste(names(freqtab[1]), "=", format(freqtab[1],
  big.mark = ",")), cex = 0.8, col = "dodgerblue")
text(max(xlim), max(ylim),
  labels = paste("Tot = ", format(sum(freqtab), big.mark = ",")), cex = 0.8,
  col = "dodgerblue", pos = 2)
day <- weekdays(as.Date(date), abbreviate = TRUE)
title(main = paste0(pkg, " @ ", date, " (", day, ")"))
```

These graphs, customized to be on the same scale, plot the _rank order_ of packages' download counts (x-axis) against the logarithm of those counts (y-axis). It then highlights a package's position in the distribution along with its rank percentile and download count (in red). In the background, the 75th, 50th and 25th percentiles are plotted as dotted vertical lines. The package with the most downloads, ['magrittr'](https://CRAN.R-project.org/package=magrittr) in both cases, is at top left (in blue). The total number of downloads is at the top right (in blue).

### III - filtering package download counts

To compute a package's downloads, we simply count the number of log entries for that package. While straightforward, this metric will eventually runs into problems because not all log entries are created equal. Some entries are, I would argue, self-evidently "invalid"; others are or debatably so. As a result, nominal package download counts are inflated, they suffer from a strictly positive, upwards bias.

This inflation is a product of software and behavioral artifacts. The software artifacts are the result of client/user side software that create log entries that are smaller, often by orders of magnitude, than a package's actual binary or source file size. The behavioral artifacts are the result of efforts to essentially download all of the packages on [CRAN](https://cran.r-project.org/).

For those interested, a prior but more detailed analysis of the inflation problem is available as part of this [post](https://blog.r-hub.io/2020/05/11/packagerank-intro/#inflationary-bias-of-download-counts) on the R-hub blog. An updated treatment is forthcoming.

#### software artifacts

Beyond missing observations (e.g., NAs for package names or package sizes; package sizes of zero bytes), the most noticeable problem when looking at download logs are wrongly sized log entries. These come in two sizes: "small" and "medium". The "small" entries are the most noticeable: they are in the neighborhood of 500 bytes. The "medium" entries are a newer phenomenon. They are variable in size, falling anywhere between a "small" and a complete download ("small" <= "medium" <= full download).

"Small" entries manifest themselves as standalone entries, paired with a full download, or as part of a triplet with a "medium" and full download. "Medium" entries manifest themselves as standalone entries, or as part of the aforementioned triplet.

Below is an excerpt from an abridged download log that illustrates a triplet:

```{r triplet}
packageLog(date = "2020-07-01")[4:6, -(4:6)]
```

The observed full download, the second entry, is 4,161,948 bytes in size (the actual binary and source files of 'cholera' version 0.7.0 are 4.0 and 4.1 MB). The "small" entry is the last observation, 536 bytes. The "medium" entry is the first observation, 99,622 bytes. Incidentally, what makes a triplet a triplet (or a pair a pair) is that all member entries have identical or adjacent timestamps. actually, information about IP address, platform, R version, etc. are also used).

"Small" entries can be easily dealt with by filtering out entries below 1000 bytes (the smallest package appears to be ['source.gist'](https://cran.r-project.org/package=source.gist) at 1200 bytes). "Medium" entries are harder to deal with. I use either a triplet-specific filter or a filter that looks up a package's real size.

#### behavioral artifacts

Wrongly sized entries are fairly visible. Less obvious are "errors" that otherwise look "right". The issue, simply put, is that package downloads don't simply reflect an interest in your package _per se_, they can also reflect an interest in [CRAN](https://cran.r-project.org/) itself: when someone downloads all the packages on [CRAN](https://cran.r-project.org/), the fact that your package got downloaded along with all the other packages shouldn't or maybe doesn't really reflect an interest in your package.

Consider the example below. It lists a bloc of downloads, in sequential time order, of the 'cholera' package:

```{r, sequence_ex}
packageLog(packages = "cholera", date = "2020-07-31")[8:14, -(4:6)]
```

Size-wise, there isn't a problem. But the fact that seven different versions were downloaded, in order, should attract our attention. This is especially true given that the bloc above represents _all_ the prior versions of 'cholera':

```{r, cholera_history}
packageHistory(package = "cholera")
```

While there are legitimate reasons for downloading prior versions (e.g., research, container-based software distribution, etc.), examples like the above probably happen more often than one would expect. The reason why is that people are literally downloading all packages from [CRAN](https://cran.r-project.org/).

I try to filter these out these efforts in two ways. The first works at the level of the log session. Using a k-means classifier, I identify IP addresses that download "too many" packages. Then, to preserve entries from "legitimate" users at the same IP address, I filter out _campaigns_, blocs of package downloads done in (nearly) alphabetical order. The second works at the level of individual packages. Since some campaigns may be associated with less "greedy" IP addresses, I also filter out sequences of past versions downloaded in some narrowly defined time window.

#### an example

To get an idea of how inflated your package's download count may be, use `filteredDownloads()`. Below are the results for 'cholera' for 31 July 2020.

```{r, filteredDownloads}
filteredDownloads(package = "cholera", date = "2020-07-31")
```

While there were 14 nominal downloads, applying all filters reduced the number of downloads to 5, an inflation of 180%.

Note that the filters are computationally demanding. Excluding the time it takes to download the log file, applying all the filters in the above example takes approximate 75 seconds using parallelized code (currently only macOS and Unix) on a 3.1 GHz Dual-Core Intel Core i5 processor.

#### limitations

There are two sets of filters. The first are CRAN specific: `ipFilter()` and `smallFilter()`. They work independently of packages, at the log or "population" level. The second are package specific: `tripletFilter()`, `sequenceFilter()`, and `sizeFilter()`. They rely on information about packages, like the size of its source or binary file.

Ideally, we'd like to use both sets of filters. However, to make valid relative comparisons (e.g., rank percentiles) we'd have to apply package specific filters for each of the tens of thousands of packages in a given log file. While feasible, this is currently very computationally expensive. For that reason, certain functions default to only use CRAN specific filters.

The functions that default to both CRAN and package specific functions are `packageLog()`, `packageCountry()`, and `filteredDownloads()`. The functions that default only to CRAN specific functions: `packageRank()`, `ipPackage()`, `countryPackage()`, `countryDistribution()` and `packageDistribution()`.

### IV - notes and miscellanea

#### country codes (top level domains)

While IP addresses are anonymized, the logs do attempt to provide the corresponding ISO country codes or top level domains (e.g., AT, JP, US). This covers about 85% of observations (i.e., approximately 15% country codes are NA). Also, for what it's worth, there seems to be a a couple of typos for country codes: "A1" (A + number one) and "A2" (A + number 2). According to [RStudio's documentation](http://cran-logs.rstudio.com/), this coding was done using MaxMind's free database, which no longer seems to be available.

#### memoization

To avoid the bottleneck of downloading multiple log files, `packageRank()` is currently limited to individual calendar dates. To reduce the bottleneck of re-downloading logs, which can be upwards of 50 MB, ['packageRank'](https://CRAN.R-project.org/package=packageRank) makes use of memoization via the ['memoise'](https://CRAN.R-project.org/package=memoise) package.

Here's relevant code:

```{r memoization, eval = FALSE}
fetchLog <- function(url) data.table::fread(url)

mfetchLog <- memoise::memoise(fetchLog)

if (RCurl::url.exists(url)) {
  cran_log <- mfetchLog(url)
}

# Note that data.table::fread() relies on R.utils::decompressFile().
```

This means that logs are intelligently cached; those that have already been downloaded, in your current R session, will not be downloaded again.

#### time zones

The calendar date (e.g. "2021-01-01") is the natural unit of observation for ['packageRank'](https://CRAN.R-project.org/package=packageRank) functions. However, because the typical use case involves the _latest_ log file, time zone differences can come into play.

Let's say that it's 09:01 on 01 January 2021 and you want to compute the rank percentile for ['ergm'](https://CRAN.R-project.org/package=ergm) for the last day of 2020. You might be tempted to enter the following expression:

```{r timezone, eval = FALSE}
packageRank(packages = "ergm")
```

However, depending on _where_ you make this request, you may not get the data you expect. If you're in Honolulu, USA, you will. If you're in Sydney, Australia, you won't. The reason is that you've somehow forgotten a key piece of trivia: RStudio typically posts yesterday's log around 17:00 UTC the following day.

The expression works in Honolulu because 09:01 HST on 01 January 2021 is 19:01 UTC 01 January 2021, so the log you want has been available for 2 hours. The expression fails in Sydney because 09:01 AEDT on 01 January 2021 is 31 December 2020 22:00 UTC. The log you want won't actually be available for another 19 hours.

To make life a little easier, ['packageRank'](https://CRAN.R-project.org/package=packageRank) does two things. First, when the date of the log you want is not available (due to time zone rather than server issues), you'll just get the last available log. If you specified a date in the future, you'll either get an error message or a warning that provides an estimate of when the log should be available.

Using the Sydney example, if you'd used the expression above, you'd get the results for 30 December 2020:

```{r sydney, eval = FALSE}
packageRank(packages = "ergm")
```
```{r sydney_code, echo = FALSE}
packageRank(packages = "ergm", date = "2020-12-30")
```

If you had specified the date, you'd get an additional warning:

```{r sydneyB, eval = FALSE}
packageRank(packages = "ergm", date = "2021-01-01")
```
```{r sydney_codeB, echo = FALSE}
packageRank(packages = "ergm", date = "2020-12-30")
```
```
Warning message:
2020-12-31 log arrives in appox. 19 hours at 02 Jan 04:00 AEDT. Using last available!
```

Second, to help you check/remember when logs are posted in your location, there's `logPostInfo()`. When you run that function, you'll get the date for the latest available log along with the expected local and UTC times when that log should be posted to RStudio's server.

Here's what you'd see in Honolulu:

```{r logPostInfo, eval = FALSE}
logPostInfo()
```

```{r logPostInfo_code, echo = FALSE, eval = FALSE}
logPostInfo(tz = "Pacific/Honolulu")
```

```
> $log.date
> [1] "2021-02-01"
>
> $GMT
> [1] "2021-02-02 17:00:00 GMT"
>
> $local
> [1] "2021-02-02 07:00:00 HST"
```

The default uses your local time zone, via `Sys.timezone()`. To use a specific time zone, pass the desired zone name from `OlsonNames()` to the `tz` argument:

```{r logPostInfo2, eval = FALSE}
logPostInfo(tz = "Australia/Sydney")
```

```
> $log.date
> [1] "2021-02-01"
>
> $GMT
> [1] "2021-02-02 17:00:00 GMT"
>
> $local
> [1] "2021-02-03 04:00:00 AEDT"
```

This functionality depends on R's ability to to compute your local time and time zone (e.g., `Sys.time()`). My understanding is that there may be operating system or platform specific issues that could affect this functionality.

#### timeout

With R 4.0.3, the timeout value for internet connections became more explicit. Here are the relevant details from that release's ["New features"](https://cran.r-project.org/doc/manuals/r-release/NEWS.html):

```
The default value for options("timeout") can be set from environment variable
R_DEFAULT_INTERNET_TIMEOUT, still defaulting to 60 (seconds) if that is not set
or invalid.
```

This change occasionally affected functions that download logs. This was especially true over slower internet connections and with larger log files. To fix this, functions that use `fetchCranLog()` will, if needed, temporarily set the timeout to 300 seconds.
